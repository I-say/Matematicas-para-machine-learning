# üå≤ Justificaci√≥n Matem√°tica: Random Forest para la Predicci√≥n de la Copa del Mundo ‚öΩ

<div align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Centro_Universitario_del_Guadalajara_Logo.png" alt="Logo CUGDL" width="300"/>
  <br>
  <strong>Centro Universitario de Guadalajara | Matem√°ticas para la Ciencia de Datos</strong>
</div>

## üìã Descripci√≥n del Proyecto

Este documento (`Justificacion_Matematica_Random_Forest.ipynb`) presenta la fundamentaci√≥n te√≥rica, matem√°tica y pr√°ctica de la elecci√≥n del algoritmo **Random Forest** como el modelo √≥ptimo para predecir los resultados de los partidos de la Copa del Mundo de la FIFA (1930-2022).

A diferencia de un an√°lisis puramente pr√°ctico, este archivo profundiza en el **"porqu√©" matem√°tico**, desglosando c√≥mo el m√©todo de *Bagging* y la selecci√≥n aleatoria de caracter√≠sticas mitigan la varianza y capturan la naturaleza estoc√°stica del f√∫tbol mejor que los modelos lineales o √°rboles simples.

## üë• Integrantes del Equipo

* **Brise√±o Esparza Paloma Astrid**
* **L√≥pez Martin V√≠ctor Hugo**
* **Medrano Gonz√°lez Christopher Josu√©**
* **Morales Cortes Miguel Isay**

**Profesor:** Iv√°n A. Toledano Ju√°rez

## üìÇ Estructura del Repositorio

Para entender el proyecto completo, tenga en cuenta los siguientes archivos:

| Archivo | Descripci√≥n |
| :--- | :--- |
| **`Justificacion_Matematica_Random_Forest.ipynb`** | **(Este archivo)** Contiene la teor√≠a, f√≥rmulas matem√°ticas (Gini, Varianza), y la defensa del modelo. |
| `PROYECTO INTEGRADOR.ipynb` | Contiene la ejecuci√≥n completa del c√≥digo, limpieza de datos, *pipelines* y generaci√≥n de predicciones. |
| `matches_1930_2022.csv` | Dataset hist√≥rico utilizado (Fuente: Kaggle). |

## üß† Fundamentos Matem√°ticos Abordados

El documento justifica la elecci√≥n del modelo bas√°ndose en:

1.  **El Problema de Clasificaci√≥n:** Definici√≥n del espacio de salida $Y \in \{1, 0, -1\}$ (Local, Empate, Visita).
2.  **Impureza de Gini:** C√≥mo el algoritmo optimiza los cortes en los nodos:
    $$G_m = 1 - \sum_{k=1}^{K} \hat{p}_{mk}^2$$
3.  **Reducci√≥n de Varianza:** Explicaci√≥n de c√≥mo el ensamble reduce el error mediante la descorrelaci√≥n de √°rboles:
    $$Var(RF) = \rho \sigma^2 + \frac{1-\rho}{B}\sigma^2$$
4.  **Compromiso Sesgo-Varianza:** Por qu√© Random Forest supera a la Regresi√≥n Log√≠stica (alto sesgo) y a los √Årboles de Decisi√≥n simples (alta varianza).

## üìä Resultados y M√©tricas

El modelo fue validado utilizando un conjunto de entrenamiento y prueba, demostrando un equilibrio √≥ptimo entre precisi√≥n y generalizaci√≥n.

* **Enfoque:** Clasificaci√≥n Supervisada Multiclase.
* **Estimadores:** 200 √°rboles de decisi√≥n.
* **M√©tricas:** Accuracy, Precision, Recall y Matriz de Confusi√≥n (visualizadas en el notebook).

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Python 3**
* **Scikit-Learn:** `RandomForestClassifier`, `Pipeline`.
* **Pandas & NumPy:** Manejo de datos y operaciones vectoriales.
* **Matplotlib & Seaborn:** Visualizaci√≥n de matrices de confusi√≥n.
* **LaTeX:** Para la formulaci√≥n matem√°tica en el notebook.

## üîó Referencias

* **Dataset:** [FIFA Football World Cup Dataset (Kaggle)](https://www.kaggle.com/datasets/piterfm/fifa-football-world-cup)
* Documentaci√≥n oficial de Scikit-Learn sobre Random Forests.

---
_Proyecto Integrador - Ciclo 2025_
